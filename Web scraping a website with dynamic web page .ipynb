{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5aa2b1",
   "metadata": {},
   "source": [
    "<center><b>Web Scraping Car Website </b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98bf69b",
   "metadata": {},
   "source": [
    "In this Progect I will be scraping the Lenz Truck center website to collect information cars which range from the selling price, make and other information. Also this shall be collected and published using an excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305546e",
   "metadata": {},
   "source": [
    "<b>Imports</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1760a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # this module helps us to download a web page\n",
    "\n",
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e89f4",
   "metadata": {},
   "source": [
    "<b>HTTP Request</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c02e3d",
   "metadata": {},
   "source": [
    "<b>Store website in a variable</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0dcc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.lenzauto.com/used-cars-and-trucks-fond-du-lac-wi?page=\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f112e",
   "metadata": {},
   "source": [
    "<b>Open a new CSV file . It can be called anything</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ed9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"scraped_LenzTruck\", \"w\")\n",
    "writer = csv.writer(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6054b",
   "metadata": {},
   "source": [
    "<b> Create a variable for writing to the CSV file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f79704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer.writerow([\"Serial Number\",\"Item Title\",\"Manufacturer\",\"Price\",\"Currency\",\"Final Url\",\"Release Date\",\"Image Url\",\"Model\",\"Color\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c38341",
   "metadata": {},
   "source": [
    "<b>Results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287e02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,46):\n",
    "    #Loop through various pages since it is dynamic \n",
    "    URL = base_url + str(x)\n",
    "    \n",
    "    #Request webpage and store it as a variable \n",
    "    urls= requests.get(URL)\n",
    "    \n",
    "    #Use Beautifulsoup to parse the html and store it as a varible \n",
    "    soup = BeautifulSoup(urls.content, \"html.parser\")\n",
    "    \n",
    "    #Find all items in the page with class attribute of 'vehicle-page'\n",
    "    results = soup.find(class_=\"vehicle-page\")\n",
    "    \n",
    "    for pages in results:\n",
    "        \n",
    "        #Find all div in the page with class attribute of 'vehicle'\n",
    "        car_elements = results.find_all('div', class_=\"vehicle\")\n",
    "        \n",
    "        for car_elements in car_elements:\n",
    "            \n",
    "            #Find all meta tags in the car_elements varible with itemprop to their corresponding item and get the content \n",
    "            serialNumber = car_elements.find('meta', {\"itemprop\": \"serialNumber\"}).get('content')\n",
    "            name = car_elements.find(\"meta\", {\"itemprop\": \"name\"}).get('content')\n",
    "            price = car_elements.find('meta',{\"itemprop\": \"price\"}).get(\"content\")\n",
    "            priceCurrency = car_elements.find('meta',{\"itemprop\":\"priceCurrency\"}).get('content')\n",
    "            url = car_elements.find(\"meta\", {\"itemprop\": \"url\"}).get('content')\n",
    "            imageUrl = car_elements.find(\"meta\", {\"itemprop\": \"image\"}).get('content')\n",
    "            manufacturer= car_elements.find(\"meta\", {\"itemprop\": \"manufacturer\"}).get('content')\n",
    "            releaseDate = car_elements.find(\"meta\", {\"itemprop\": \"releaseDate\"}).get('content')\n",
    "            Model = car_elements.find(\"meta\", {\"itemprop\": \"model\"}).get('content')\n",
    "            color = car_elements.find(\"meta\", {\"itemprop\": \"color\"}).get('content')\n",
    "            \n",
    "            #LOOP THROUGH BOTH LISTS USING THE 'ZIP' FUNCTION\n",
    "            #WRITE EACH ITEM AS A NEW ROW IN THE CSV\n",
    "            writer.writerow([serialNumber,name,manufacturer, price,priceCurrency,url,releaseDate,imageUrl,Model,color])\n",
    "            #print(serialNumber+ \"-\" +name+ \"-\" +manufacturer+ \"-\" +price+ \"-\" +priceCurrency+ \"-\" +url+ \"-\" +releaseDate+ \"-\" +imageUrl+ \"-\" +Model+ \"-\" +color)\n",
    "\n",
    "#CLOSE THE CSV FILE\n",
    "file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf7480",
   "metadata": {},
   "source": [
    "<center><b>THE  END </b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20117f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
